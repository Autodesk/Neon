{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Neon's home","text":"<p>Neon is a research framework for programming multi-device systems maintained by Autodesk Research.  Neon\u2019s goal is to automatically transform user sequential code into, for example, a scalable multi-GPU execution.</p> <p></p> <p>To reach its goal, Neon takes a domain-specific approach based on the parallel skeleton philosophy (a.k.a parallel patterns).  Neon provides a set of domain-specific and programmable patterns that users compose through a sequential programming model to author their applications.  Then, thanks to the knowledge of the domain, the patterns and their composition, Neon automatically optimizes the sequential code into an execution optimized for multi-device systems. Currently, Neon targets grid-based computations on multi-core CPUs or single node multi-GPU systems.</p> <p>Warning</p> <p>It is important to keep in mind that Neon is a research project in continuous evolution.  So, while we have successfully tested the system with different applications (Finite Difference, Finite Element, Lattice Boltzmann Method), Neon interfaces may change between versions to introduce new capabilities. </p> <p>The rest of the documentation is structured as follows:</p> Learn: a set of simple blog-post-style tutorials to help new users to get used to Neon syntax and mechanisms.  References information about the project, like publications, presentation, API documentation and performance analysis of the benchmarks included in Neon.  Gallery a collection of plots, simulation outputs that showcase Neon capabilities on different applications Community information of the community, from how to collaborate to Neon and to a list of current and past contributors."},{"location":"CODE_OF_CONDUCT/","title":"Code of Conduct","text":""},{"location":"CODE_OF_CONDUCT/#our-pledge","title":"Our Pledge","text":"<p>We as members, contributors, and leaders pledge to make participation in our community a safe, inclusive and harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive and healthy community.</p>"},{"location":"CODE_OF_CONDUCT/#our-standards","title":"Our Standards","text":"<p>Our Open Source Community works to:</p> <ul> <li>Be kind towards other people which enables us to be empathic to each other</li> <li>Be respectful of differing opinions, viewpoints, and experiences</li> <li>Give and gracefully accept constructive feedback</li> <li>Accept responsibility and apologize to those affected by our mistakes, and learning from the experience</li> <li>Focus on what is best not just for us as individuals, but for the overall community</li> </ul> <p>We will not tolerate the following behaviors: + Violent threats or language + The use of sexualized language or imagery, and sexual attention or advances of any kind + Trolling, insulting or derogatory comments, and personal or political attacks + Public or private harassment + Publishing others\u2019 private information, such as a physical or email address, without their explicit permission + Other conduct which could reasonably be considered inappropriate in a professional setting</p>"},{"location":"CONTRIBUTING/","title":"Neon\u2019s Community and How to Contribute","text":"<p>The Neon team strongly believes in the open-source effort and we welcome and greatly appreciate contributions from the community: proposing new features, filing issues, and contributing code. The rest of the document describes various processes to give your contribution. </p>"},{"location":"CONTRIBUTING/#providing-suggestions","title":"Providing Suggestions","text":"<p>Neon is meant to evolve with feedback from the community, and we greatly appreciate any thoughts on ways to improve the design or features. Please use the <code>enhancement</code> tag to denote issues that are suggestions specifically\u2014this helps us triage and respond appropriately.</p>"},{"location":"CONTRIBUTING/#filing-bugs","title":"Filing Bugs","text":"<p>As with all software, you may run into bugs. Please submit bugs as regular issues on GitHub\u2014we are regularly monitoring issues and will prioritize and schedule fixes.</p> <p>The best bug reports include a detailed way to reproduce the issue predictably and possibly even a working example demonstrating the issue.</p>"},{"location":"CONTRIBUTING/#contributing-code","title":"Contributing Code","text":"<p>There are three main steps for contributing your code to the project. First, sign a Contributor License Agreement, share your goal with the community, write your code following Neon coding standards, and finally, submit a pull request. Here are some more details on each of the steps.</p>"},{"location":"CONTRIBUTING/#contributor-license-agreement-cla","title":"Contributor License Agreement (CLA)","text":"<p>Before contributing any code to this project, we kindly ask you to sign a Contributor License Agreement (CLA). We can not accept any pull request if a CLA has not been signed.</p> <ul> <li> <p>If you are contributing on behalf of yourself, the CLA signature is included as a part of the pull request process.</p> </li> <li> <p>If you are contributing on behalf of your employer, please sign our Corporate Contributor License Agreement. The document includes instructions on where to send the completed forms to. Once a signed form has been received, we can happily review and accept your pull requests.</p> </li> </ul>"},{"location":"CONTRIBUTING/#coordinate-with-the-community","title":"Coordinate With the Community","text":"<p>We highly recommend opening an issue on GitHub to describe your goals before starting any coding. This will allow you to get early feedback and avoid multiple parallel efforts.</p>"},{"location":"CONTRIBUTING/#coding-standard","title":"Coding Standard","text":"<p>To provide a more uniform code base, we would appreciate it if any new code could follow the coding standard described in this document: CodeConvention.md.</p>"},{"location":"CONTRIBUTING/#git-workflow","title":"Git Workflow","text":"<p>We follow the GitFlow development model.  If you would like to contribute your code to Neon, you should: - Include your work in a feature branch created from the Neon <code>develop</code> branch. The <code>develop</code> branch contains the latest work in Neon.  - Then, create a pull request against the <code>develop</code> branch.</p> <p>Periodically, we merge the develop branch into the <code>main</code> branch and tag a new release.</p> <p>When contributing code, please include appropriate tests as part of the pull request, and follow the same comment and coding style as the rest of the project. Take a look through the existing code for examples of the testing and style practices the project follows.</p>"},{"location":"CONTRIBUTORS/","title":"Contributors","text":"<p>We are extremely thankful to all the contributors to the project. A complete list can be found at GitHub Contributors Page.</p> <p>We also want to thank everyone who contributed to Neon before it was made open source.  Since the history of the Neon internal version was not migrated to GitHub, their names may not appear on the GitHub Contributors Page.</p> <pre><code>Ahmed Mahmoud\nAli Hashemi\nBrooke Dolny\nMassimiliano Meneghin\nNigel Morris\nPradeep Kumar Jayaraman\n</code></pre> <p>Finally, we also want to thank everyone from Autodesk who supported the project and made an open-source Neon a reality. </p>"},{"location":"CodeConvention/","title":"CodeConvention","text":""},{"location":"CodeConvention/#neon-code-convention","title":"Neon Code Convention","text":""},{"location":"CodeConvention/#general-rules","title":"General rules:","text":"<ul> <li>Use doxgen for documentation with Javadoc style comment block i.e.,      <pre><code>/**\n * ... text ...\n */\n</code></pre></li> <li> <p>Use inline documentation of the function input variables and class members variables e.g.,      <pre><code>void foo(int v /**&lt; [in] docs for input parameter v */);\n</code></pre></p> </li> <li> <p><code>using namespace</code> is only allowed inside <code>.cpp</code>/<code>.cu</code> files. It\u2019s disallowed in headers.</p> </li> <li> <p><code>using namespace std</code> is disallowed even in <code>.cpp</code>/<code>.cu</code> files. If you want to save some work, just typedef the type you need from the std namespace, or use <code>auto</code>.</p> </li> <li> <p>For consistency reasons, use <code>using</code> declaration instead of <code>typedef</code> e.g.,     <pre><code>using UintVector = std::vector&lt;uint32_t&gt;;\n</code></pre></p> </li> <li> <p>Use only sized types (e.g., <code>int32_t</code>, <code>uint32_t</code>, <code>int16_t</code>). Conceptually, <code>bool</code> has unknown size, so no size equivalent. <code>char</code> is special and can be used only for C strings (use <code>int8_t</code> otherwise).</p> </li> <li> <p>Don\u2019t use <code>NULL</code> or 0 to initialize pointers. <code>nullptr</code> is part of the language now.</p> </li> <li> <p>Preprocessor definitions are all capitals and may contain <code>_</code> e.g.,      <code>c++      #define SOME_DEFINE</code></p> </li> <li> <p>Don\u2019t use long line comment separator e.g., <code>/////////////</code> or <code>/*****************/</code></p> </li> <li> <p>We use <code>NEON_TRACE</code>, <code>NEON_INFO</code>, <code>NEON_WARNING</code>, <code>NEON_ERROR</code>, and <code>NEON_CRITICAL</code> for logging. Using <code>printf</code> or <code>std::cout</code> is prohibited. <code>NEON_*</code> logging macro rely on <code>spdlog</code> with easy python-like string formatting e.g.,      <pre><code>NEON_INFO(\"Welcome to spdlog!\");\nNEON_ERROR(\"Some error message with arg: {}\", 1);\n\nNEON_WARNING(\"Easy padding in numbers like {:08d}\", 12);\nNEON_CRITICAL(\"Support for int: {0:d};  hex: {0:x};  oct: {0:o}; bin: {0:b}\", 42);\nNEON_INFO(\"Support for floats {:03.2f}\", 1.23456);\nNEON_INFO(\"Positional args are {1} {0}..\", \"too\", \"supported\");\nNEON_INFO(\"{:&lt;30}\", \"left aligned\");\n</code></pre></p> </li> </ul>"},{"location":"CodeConvention/#variable-prefixes","title":"Variable prefixes:","text":"<p>Use the following prefixes for variable names based on the scope <code>s</code>, <code>m</code>, <code>g</code>, and <code>k</code>. These are mutually exclusive prefixes, where <code>k</code> takes precedence above the rest.  - <code>k</code> for compile-time const variables.  - <code>g</code> for global variables, including static global variables.  - <code>s</code> for class static variables.  - <code>m</code> for member variables in classes (not in structs).</p> <p>In addition <code>p</code> is used for pointers e.g.,</p> <pre><code>//Global Variables:\nconst uint32_t kConstGlobal; // compile-time-const, so 'k' takes precedence\nint32_t gSomeGlobal;         // global start with 'g'\nstatic int gStaticGlobal;    // Static globals start with 'g'\nvoid* gpSomePointer;         // Global variables which is a pointer is prefixed with 'gp'\nconst void* gpPointer2;      // Not compile-time constant.\n</code></pre>"},{"location":"CodeConvention/#functions","title":"Functions:","text":"<ul> <li> <p>Use auto style for function but explicitly defining the return type using trailing arrow e.g., <pre><code>auto getGirdSize() -&gt; int;\n</code></pre></p> </li> <li> <p>Function names should be descriptive:</p> </li> <li>Functions that perform an action should be named after the action it performs e.g., <code>Fbo::clear()</code>, <code>createTextureFromFile()</code>.</li> <li>Getters/Setters should start with <code>get</code> and <code>set</code></li> <li> <p>Functions names that return a <code>bool</code> should be phrased as a question e.g., <code>isWhite()</code>, <code>doesFileExist()</code>, <code>hasTexture()</code></p> </li> <li> <p>Function names are lower-camel-case e.g.,  <pre><code>void someFunction()\n</code></pre></p> </li> </ul>"},{"location":"CodeConvention/#classes","title":"Classes:","text":"<ul> <li> <p>Classes should hide their internal data as much as possible.</p> </li> <li> <p>Class names should be Upper Camel case (<code>UpperCamelClass</code>) or Lower Camel case (<code>lowerCamelClass</code>)</p> </li> </ul> <pre><code>class UpperCamelClass\n{\n\n    bool isValid();                // Function names are lower-camel-case\n    static uint32_t sInt;          // Static variables start with 's'\n    static const uint32_t kValue;  // Const static is prefixed with 'k'\n    int32_t mMemberVar;           // Member variables start with 'm'\n    int16_t* mpSomePointer;       // Note that with a pointer variable, \"p\" counts as the first word, so the next letter *is* capitalized\n};\n</code></pre> <ul> <li> <p>Header file must be a <code>.h</code> containing only the class declaration i.e., class name, methods\u2019 signature and variables</p> </li> <li> <p>Source file must be a <code>.cpp</code> or <code>.cu</code> and it contains the definition of all methods</p> </li> <li> <p>Templated methods definition must be in separate <code>.h</code> file that is included by the corresponding <code>.h</code>. File name should end with <code>_imp.h</code></p> </li> <li> <p>File names only contain dot (\u201c.\u201d) before the file extension suffix</p> </li> <li> <p>Each class has it\u2019s own files with same name e.g., <code>Grid</code> class goes into <code>Grid.h</code>, <code>Grid.cpp</code>, and <code>Grid_imp.h</code></p> </li> <li> <p>The order of public/private members and methods as they appear in the class <code>.h</code> file is:</p> <ol> <li>public members</li> <li>public methods</li> <li>private methods</li> <li>private members</li> </ol> </li> </ul> <pre><code>// Grid.h\n#pragma once\nnamespace Neon::grid {\n/**\n * Grid is the blueprint of creating physical domains \n*/\nclass Grid\n{\n   private:   \n    int mNumCells = 0 /**&lt; number of cells */;\n\n   public:\n    /**\n     * default constructor \n    */\n    Grid() = default;\n\n    /**\n     * Grid constructor      \n    */\n    Grid(int&amp; const bool padding /**&lt; [in] Enable memory padding if true */);\n\n    /**\n     * Create new field      \n     * @return the new field \n    */\n    template &lt;typename T /**&lt; Field type */&gt;\n    auto newField() -&gt; Grid::Field&lt;T&gt;;\n\n\n};\n}  // namespace Neon::grid\n#include \"Neon/domain/Grid_imp.h\"\n</code></pre> <pre><code>// Grid.cpp\n#pragma once\n#include \"Neon/domain/Grid.h\"\nnamspeace Neon::grid {\n    Grid::Grid(int&amp; const bool padding){\n        // ....\n    }\n} // namspeace Neon::grid \n</code></pre> <pre><code>//Grid_imp.h\n#pragma once\n#include \"Neon/domain/Grid.h\"\nnamspeace Neon::grid {\n    template&lt;typename T&gt;\n    auto Grid::newField() -&gt; Grid::Field&lt;T&gt;{        \n        //...        \n    }\n} // namspeace Neon::grid \n</code></pre>"},{"location":"CodeConvention/#structs","title":"Structs:","text":"<p>Use struct only as a data-container. All fields must be public. No member functions are allowed. In-class initialization is allowed.</p> <pre><code>//UpperCamelStruct.h\nstruct UpperCamelStruct\n{\n    int32_t someVar;               // Struct members are lower-camel-case    \n    int32_t** pDoublePointer;      // Double pointer is just a pointer\n    std::smart_ptr&lt;int&gt; pSmartPtr; // Smart pointer is a pointer\n    char charArray[];              // Array is not a pointer\n    std::string myString;          // String is a string\n    bool isBoolean;                // bool name implies that it's a bool. 'enable', 'is*', 'has*', etc. Don't use negative meaning (use 'enable' instead of 'disable')\n    uint32_t&amp; refVal;              // Reference is not a pointer\n};\n</code></pre>"},{"location":"CodeConvention/#enums","title":"Enums:","text":"<p>Use typed enums (i.e, <code>enum class</code>) as they are type safe and they automatically define their namespace. When approperiate, each enum class should be followed by utility class with static methods. These utility method provide a <code>toString()</code> funtionality as well as <code>toInt()</code> for easy conversions.</p> <pre><code>//DataView.h\nenum class DataView : char {\n    standard,\n    internal, \n    boundary\n};\nclass DataViewUtils {\n    static auto toString(DataView d) -&gt; std::string;\n    static auto toInt(DataView d) -&gt; int;\n}\n</code></pre>"},{"location":"maintainers/","title":"Current Maintainers","text":"<p>The current maintainers of project Neon are:</p> Massimiliano Meneghin Ahmed Mahmoud Autodesk Research Autodesk Research"},{"location":"gallery/apps/","title":"Applications","text":"Julia Set Fractal 2D LBM (K\u00e1rm\u00e1n Vortex Street) Game of Life Poisson CG Solver 3D LBM (Lid-driven cavity)"},{"location":"learn/guided-tutorials-introduction/","title":"Guided Tutorial - Introduction","text":"<p>Neon aims at making multi-XPU programming easier for computations on volumetric data structure by providing users with a simple sequential programming model, while automatically applying varius optimizations under the hood.</p> <p>Nowadays, accelerators are at the core of high performance computing and they   come in different types and configurations. Term XPU has been introduced as generic term to capture the diversity of accelerators, GPU, FPGA, TPU etc. We target a collection of XPU computing accelerators that can be connected in shared memory or distributed fashion. While this is the long-term scope of the project, at the moment, we support shared memory CPU and GPUs. In particular, our current implementation is based on openMP (on CPU) and CUDA (on GPU).</p> <p>Volumetric data structures are used as a way to create a digital representation of properties of three-dimensional objects. For example, we can use them to represent pressure, displacement or material properties. Volumetric data structures are used both in simulation and computer graphics tools. </p> <p>Automatic parallelization of generic sequential code is still an open challenge which could be referred as the holy grail for the HPC community.  Neon addresses a more tractable challenge by restricting the problem to specific domains. Neon focus on problems based on regular spatial discretions like uniform cartesian grids (support for non-uniform cartesian is in development). </p> <p>Moreover, Neon primarily support local operations like map (the value of a cell depends only on the metadata stored in the same cell) or stencil (a cell value is computed using metadata associated to close cells). Reductions (like dot or norm) are the only global operations in Neon. Thanks to the information on both the structure of volumetric representation and the supported operations, Neon is able to automatically decompose the problem domain in different partitions, map partitions to available XPUs, handle any required communication between partitions and finally to organize the computation to introduce optimizations like overlapping computation and communication which are essential to achieve good performance.  </p> <p>We use the following simple example of three operations (AXPY, Laplace and dot) to showcase the operation that are done by Neon under the hood.</p> Simple user application in Neon and its dependency graph <p>As first step, Neon parses the user code and creates a data dependency graph of the application. The dependency graph is then extended into a multi-GPU graph, where required communication between GPUs have been added. </p> Different Multi-XPU Graph created by Neon <p>The multi-GPU graph, however, is just the starting point. Indeed Neon can apply a set of optimization to enable overlapping of computation and communication to improve scalability. All this optimization are entirely transparent to the users who focus on authoring code following a sequential programming model.</p> <p>The structure of Neon is based ona set of abstraction levels, each one represented by a C++ library.</p> <p></p> <p>The Domain and Skeleton are the most important abstraction for Neon users. The Domain level introduces domain-specific mechanisms, currently Neon targets voxel based computations: mechanisms are Cartesian grids, fields and stencils. The Skeleton level provides users with a sequential programming model and in charge of transforming and optimizing user applications to be deployed into a multi-device system. The Skeleton abstraction has its roots in the fields of parallel patterns and skeleton. </p> <p>Both the Domain and Skeleton rely on the other Neon abstraction levels: the System,  abstracts the specific XPU capabilities,  and the Set Set provides a simple interface to manage a set of XPUs. </p> <p>The following is the structure of the <code>Introduction and tutorial</code> section:</p> <p>Note</p> <p>To learn how to write an application with Neon, new users can mainly focus on the Domain (link) and Skeleton (link) documentation as it implicitelly covers all the nedded information from the other Neon abtraction levels. </p>"},{"location":"learn/staggered-grids/staggered-grid/","title":"Staggered Grids","text":""},{"location":"learn/staggered-grids/staggered-grid/#staggered-grids-experimental-wip","title":"Staggered Grids - Experimental [WIP]","text":"<p>Staggered grids are crucial for numerical methods like the finite element method. Neon natively provides a staggered-grid abstraction over Neon uniform grids. In other words, we can create a staggered grid using any of the uniform grids such as dGrid (dense), eGrid (sparse), bGrid (sparse).</p> <p>Node Grid and Voxel Grid are Neon\u2019s terminology to distinguish between the primal and dual grid of a staggered configuration. The following image is just a 2D example of a staggered grid for a sparse uniform discrete domain; the node grid is highlighted in blue, and the voxel grid is in green.</p> <p> </p> <p>Node Grid and Voxel Grid provide the same compute API that Neon uniform grids offer. However, they also include functionality to jump from nodes to voxels and vice-versa.</p> <p>Staggered grid provides mechanisms to create containers running on nodes or voxels. The created containers are fully compatible with the Neon Skeleton model.</p> <p>For this tutorial we want to showcase Neon StaggeredGrid mechanism with some simple operations, where we represent temperature and density properties respectively on nodes and voxels. The operations do not have actual physical meaning and their sole porpoise if to show some common type of computations in a simple context.</p> <ul> <li>** Step 0 - Initialization of a staggered grid **. The StaggeredGrid initialization process is   slightly   different than the ones of uniform grids.   We will be using a small 2 by 3 by 9 voxel grid.</li> <li>** Step 1 - Initialization of node and voxel fields **. We\u2019ll be using nodes to store   temperature   and voxels to store material density.</li> <li>** Step 2 - Access to neighbouring nodes **. We\u2019ll be looping around the   neighbouring nodes of a voxel to sum up their temperature values.</li> <li>** Step 3 - Access to neighbouring voxels **. We\u2019ll be accessing   neighbouring   voxels of a node to sum up their density values and to divide tha result by 8.   The division by 8 will highlight some topological characteristics of the dual grids that we can use to confirm the   actual results.</li> </ul> <p>The code of the tutorial can be found in the Neon repository (<code>Neon/staggered-grid/tutorials/staggered-grids</code>). As on the other tutorial in the rest will start from a emtpy main and we\u2019ll looking at how to implement the previous steps.</p> <p>"},{"location":"learn/staggered-grids/staggered-grid/#step-0-initialization-of-a-staggered-grid","title":"** Step 0 - Initialization of a staggered grid **","text":"<p>The initialization code is straightforward. As always we first have to define the hardware configuration for the execution by creating a <code>Backend</code> object.</p> <p>Similarly to uniform grids, we also provide the dimension of the background grid and a sparsity mask through a lambda function. For this last part of the process we target solely information of the voxel grid. Thanks to the property of staggered grids, can reconstruct all the required information for the node grid.</p> <p>Again as for the other Neon uniform grids, the last parameter is a list of stencil that will be used for computation on the staggered grid. The stencil shape can be used either on the node and on the voxel grid. Even with an empty stencil list, the staggered grid will include the support for stencil operation for node to neighboring voxel and vice versa.</p> Neon/tutorials/staggered-grids/src/staggeredGrid.cpp<pre><code>int main()\n{// Selecting the hardware for the computation\n    Neon::Backend backend = [] {\n        Neon::init();\n        // Our XPU will be a CPU device.\n        auto runtime = Neon::Runtime::openmp;\n        // We are overbooking XPU 0 two times\n        std::vector&lt;int&gt; gpu_ids{0, 0};\n        Neon::Backend    backend(gpu_ids, runtime);\n        return backend;\n    }();\n\n    // Define an alias for our staggered grid\n    using UniformGrid = Neon::domain::dGrid;\n    using StaggeredGrid = Neon::domain::internal::experimental::staggeredGrid::StaggeredGrid&lt;UniformGrid&gt;;\n    using FP = double;\n    using UserContainers = tools::Containers&lt;StaggeredGrid, FP&gt;;\n\n    // Initializing a staggered grid based on dGrid\n    StaggeredGrid grid = [&amp;] {\n        // Setting the dimension for the voxel grid\n        Neon::int32_3d voxDims{2, 3, 9};\n\n        // For our tutorial, we don't need to add new stencil.\n        // By default, the staggered grid will add the stencil\n        // to move from voxel to node and vice versa\n        std::vector&lt;Neon::domain::Stencil&gt; noExtraStencils;\n\n        StaggeredGrid newGrid(\n            backend,\n            voxDims,\n            [](const Neon::index_3d&amp;) -&gt; bool {\n                return true;\n            },\n            noExtraStencils);\n\n        return newGrid;\n    }();\n\n    return 0;\n}\n</code></pre> <p>"},{"location":"learn/staggered-grids/staggered-grid/#step-1-initialization-of-node-and-voxel-fields","title":"** Step 1 - Initialization of node and voxel fields **","text":"<p>We now extend the previous code with the initialization of the temperature and density fields. The process is identical to the one used for uniform grids.</p> <p>To make the things more interesting, we used two different method to initialize the two fields. In the density case, we used the host side interface, while for the temperature the initialization happens on the XPU side.</p> <p>Note</p> <p>The density fiels data have to manually be tranfered from the host to the XPUs,  bacause the initilization was done on the host size.</p> Neon/tutorials/staggered-grids/src/staggeredGrid.cpp<pre><code>    // ...\n\n    auto density = [&amp;grid] {\n        // Defining a voxel field to represent the density of each voxel\n        // We then set its initial values to zero in the host (CPU),\n        // and finally we transfer the data to the XPU\n        auto density = grid.template newVoxelField&lt;FP, 1&gt;(\"Density\", 1, 0);\n        density.forEachActiveCell([](const Neon::index_3d&amp; /*idx*/,\n                                     const int&amp; /*cardinality*/,\n                                     FP&amp; value) {\n            value = 0;\n        });\n        density.updateCompute(Neon::Backend::mainStreamIdx);\n        return density;\n    }();\n\n    auto temperature = [&amp;grid] {\n        // Defining a node field to represent the temperature at each node\n        // We then set its initial values to one, but to make it more interesting,\n        // we do the initialization directly on the device calling a Containers.\n        // Note that in this case we don't need to transfer data from host to XPUs\n        auto temperature = grid.template newNodeField&lt;FP, 1&gt;(\"Temperature\", 1, 0);\n        temperature.forEachActiveCell([](const Neon::index_3d&amp; /*idx*/,\n                                         const int&amp; /*cardinality*/,\n                                         FP&amp; value) {\n            value = 0;\n        });\n        UserContainers::resetValue(temperature, FP(1.0)).run(Neon::Backend::mainStreamIdx);\n        return temperature;\n    }();\n\n    // We define a simple function to export to vtk both\n    // temperature and density field during each step of the tutorial.\n    auto exportingToVti = [&amp;](const std::string&amp; tutorialStepId) {\n        {  // Moving memory from XPUs to CPU\n            temperature.updateIO(Neon::Backend::mainStreamIdx);\n            density.updateIO(Neon::Backend::mainStreamIdx);\n            backend.sync(Neon::Backend::mainStreamIdx);\n        }\n        {  // Exporting the results\n            const std::string appName(\"staggered-grid\");\n            temperature.ioToVtk(appName + \"-temperature-\" + tutorialStepId, \"temperature\", false, Neon::IoFileType::BINARY);\n            density.ioToVtk(appName + \"-density-\" + tutorialStepId, \"density\");\n        }\n    };\n\n    // We are exporting to vtk the values of the fields after the initialization.\n    // We expect all temperature nodes to be set to one,\n    // and all density voxels to be set to zero.\n    exportingToVti(\"0000\");\n\n    return 0;\n}\n</code></pre> <p>The following is the code for the XPU side initialization of the temperature field shows how to define a Neon Container on a staggered grid. The structure should result quite familiar at this point. There are two minor changes that are highlighter in the code below. Firstly, the method for creating a container is now specific for node and voxel grids (<code>getContainerOnNodes</code> and <code>getContainerOnVoxel</code>). And finally, the parameter of the Neon Compute Lambda has changed from <code>Idx</code>, to<code>Node</code> and <code>Voxel</code>.</p> Neon/staggered-grid/tutorials/staggered-grids/src/containers.cu<pre><code>template &lt;typename StaggeredGrid, typename T&gt;\nauto Containers&lt;StaggeredGrid, T&gt;::resetValue(Self::NodeField  field,\n                                              const Self::Type alpha) -&gt; Neon::set::Container\n{\n    return field.getGrid().getContainerOnNodes(\n        \"addConstOnNodes\",\n        // Neon Loading Lamnbda \n        [&amp;](Neon::set::Loader&amp; loader) {\n            auto&amp; out = loader.load(field);\n\n            // Neon Compute Lambda\n            return [=] NEON_CUDA_HOST_DEVICE(const typename Self::NodeField::Node&amp; e) mutable {\n                for (int i = 0; i &lt; out.cardinality(); i++) {\n                    out(e, i) = alpha;\n                }\n            };\n        });\n}\n</code></pre> <p>In the main function code, just after the field initialization we added a helper function to export Staggered grid data to XPU. The function takes also care of moving data from XPUs to host. Again the method to export to VTK is the same as for uniform grids. To add some variety to the tutorial, temperature fields are exported in a VTK binary format.</p> <p>The call to the export function at the end of the previous main function code show us how the data has been initialized. As we can see from the following screenshot, temperature nodes are al set to 1 and density voxel to zero.</p> <p></p> <p>"},{"location":"learn/staggered-grids/staggered-grid/#step-2-access-to-neighbouring-nodes","title":"** Step 2 - Access to neighbouring nodes **","text":"<p>Let\u2019s now focus on how to do some stencil computation, we for each temperature node we want to access the value of neighbouring density voxels.</p> <p>We know that the in Neon the identification of a neighbour Idx of a uniform grid is done through 3D offsets. For example if I want to identify the cell on the left (in the positive X direction), we use the 3D offset {1,0,0}. The same abstraction is valid for stencil operation between nodes or between voxels.</p> <p>The 3D offset abstraction is extended also to jumps between node and voxel grids as shown by the following example in 2D.</p> <p> </p> <p>Notes</p> <ul> <li>In a jump beteen node and voxel grids, only the niarest neightours can be accesses (stencil of radious one). </li> <li>The componed of a 3D offset for a grid jump are always 1 or -1, and 0 is not a valid option.</li> <li>While the offset {1,1,1} can be both associated with a standard stencil operation and a grid jump,    the actual semantic is extracted by the context (i.e. the method it is called with).</li> </ul> <p>Now that we know how 3D offsets are formalized for the jump between primal and dual grids like in the following snipped of code, where we create container that sums up the temperature values of the neighboring nodes and stores it in the voxel.</p> Neon/tutorials/staggered-grids/src/containers.cu<pre><code>template &lt;typename StaggeredGrid, typename T&gt;\nauto Containers&lt;StaggeredGrid, T&gt;::sumNodesOnVoxels(Self::VoxelField&amp;      densityField,\n                                                    const Self::NodeField&amp; temperatureField)\n    -&gt; Neon::set::Container\n{\n    return densityField.getGrid().getContainerOnVoxels(\n        \"sumNodesOnVoxels\",\n        // Neon Loading Lambda\n        [&amp;](Neon::set::Loader&amp; loader) {\n            auto&amp;       density = loader.load(densityField);\n            const auto&amp; temperature = loader.load(temperatureField, Neon::Pattern::STENCIL);\n\n            // Neon Pattern Lambda\n            return [=] NEON_CUDA_HOST_DEVICE(const typename Self::VoxelField::Voxel&amp; voxHandle) mutable {\n                Type          sum = 0;\n                constexpr int componentId = 0;\n\n                // We visit all the neighbour nodes around voxHandle.\n                // Relative discrete offers are used to identify the neighbour node.\n                // As by construction all nodes of a voxel are active, we don't have to do any extra check.\n                sum += temperature.template getNghNodeValue&lt;1, 1, 1&gt;(voxHandle, componentId);\n                sum += temperature.template getNghNodeValue&lt;1, 1, -1&gt;(voxHandle, componentId);\n                sum += temperature.template getNghNodeValue&lt;1, -1, 1&gt;(voxHandle, componentId);\n                sum += temperature.template getNghNodeValue&lt;1, -1, -1&gt;(voxHandle, componentId);\n                sum += temperature.template getNghNodeValue&lt;-1, 1, 1&gt;(voxHandle, componentId);\n                sum += temperature.template getNghNodeValue&lt;-1, 1, -1&gt;(voxHandle, componentId);\n                sum += temperature.template getNghNodeValue&lt;-1, -1, 1&gt;(voxHandle, componentId);\n                sum += temperature.template getNghNodeValue&lt;-1, -1, -1&gt;(voxHandle, componentId);\n\n                // Storing the final result in the target voxel.\n                density(voxHandle, 0) = sum;\n            };\n        });\n}\n</code></pre> <p>Now that we now have our container, we just need to extend our main function to run it, and export the data to vti to check the result.</p> Neon/tutorials/staggered-grids/src/staggeredGrid.cpp<pre><code>    // ... \n\n    {  // Accessing voxels from nodes\n       // For each node we loop around active voxel, and we sum their values.\n       // At the end of this operation we expect all voxel to store a value of 8,\n       // as there are 8 nodes for each voxel, each one set to one.\n        UserContainers::sumNodesOnVoxels(density, temperature)\n            .run(Neon::Backend::mainStreamIdx);\n\n        exportingToVti(\"0001\");\n    }\n\n    return 0;\n}\n</code></pre> <p>Warning</p> <p>The <code>sumNodesOnVoxels</code> Container represents a stencil opertation, therefore the halo of the temperature field must be up to  date before executing the container. There are two wasy for addressing this, we can update the halo manually (as in the tutorial code) or we can use the Skeleton. In this tutorial we choose the first solution as we are showcasing mechanisms at the Domain level. Finally, the  halo update code is in the tutorial code but has not reported here as it is not the focus out topic: Staggered grids.</p> <p>The resulting visualization of the results is not exciting, but it conforms that it confirms that the code is working: all temperature nodes are still set to one as in the initialization step while all density voxel are now set to 8. This is exactly the result we were expecting as each voxel is surrounded by exactly 8 voxels.</p> <p></p> <p>"},{"location":"learn/staggered-grids/staggered-grid/#step-3-access-to-neighbouring-voxels","title":"** Step 3 - Access to neighbouring voxels **","text":"<p>In this last step we implement a container that given a nodes it fetches values from all the neighbouring density voxels, sum them up, and it finally stores one with of the sum into the node temperature value.</p> Neon/tutorials/staggered-grids/src/containers.cu<pre><code>template &lt;typename StaggeredGrid, typename T&gt;\nauto Containers&lt;StaggeredGrid, T&gt;::sumVoxelsOnNodesAndDivideBy8(Self::NodeField&amp;        temperatureField,\n                                                                const Self::VoxelField&amp; densityField) -&gt; Neon::set::Container\n{\n    return temperatureField.getGrid().getContainerOnNodes(\n        \"sumVoxelsOnNodesAndDivideBy8\",\n        // Neon Loading Lambda\n        [&amp;](Neon::set::Loader&amp; loader) {\n            const auto&amp; density = loader.load(densityField, Neon::Pattern::STENCIL);\n            auto&amp;       temperature = loader.load(temperatureField);\n\n            auto nodeSpaceDim = temperatureField.getGrid().getDimension();\n\n            // Neon Pattern Lambda\n            return [=] NEON_CUDA_HOST_DEVICE(const typename Self::NodeField::Node&amp; nodeHandle) mutable {\n                Type sum = 0;\n\n                constexpr int componentId = 0;\n                constexpr int returnValueIfVoxelIsNotActive = 0;\n\n                // We visit all the neighbouring voxels around nodeHandle.\n                // Relative discrete offers are used to identify the neighbour node.\n                // Note that some neighbouring nodes may be not active.\n                // Rather than explicitly checking we ask Neon to return 0 if the node is not active.\n                sum += density.template getNghVoxelValue&lt;1, 1, 1&gt;(nodeHandle, componentId, returnValueIfVoxelIsNotActive).value;\n                sum += density.template getNghVoxelValue&lt;1, 1, -1&gt;(nodeHandle, componentId, returnValueIfVoxelIsNotActive).value;\n                sum += density.template getNghVoxelValue&lt;1, -1, 1&gt;(nodeHandle, componentId, returnValueIfVoxelIsNotActive).value;\n                sum += density.template getNghVoxelValue&lt;1, -1, -1&gt;(nodeHandle, componentId, returnValueIfVoxelIsNotActive).value;\n                sum += density.template getNghVoxelValue&lt;-1, 1, 1&gt;(nodeHandle, componentId, returnValueIfVoxelIsNotActive).value;\n                sum += density.template getNghVoxelValue&lt;-1, 1, -1&gt;(nodeHandle, componentId, returnValueIfVoxelIsNotActive).value;\n                sum += density.template getNghVoxelValue&lt;-1, -1, 1&gt;(nodeHandle, componentId, returnValueIfVoxelIsNotActive).value;\n                sum += density.template getNghVoxelValue&lt;-1, -1, -1&gt;(nodeHandle, componentId, returnValueIfVoxelIsNotActive).value;\n\n                // Storing the final result in the target node.\n                temperature(nodeHandle, 0) = sum / 8;\n            };\n        });\n}\n</code></pre> <p>The structure of the above Container is the similar to the previous one. However <code>getNghVoxelValue</code> has a different signature. Indeed, while all nodes of a voxel are active by construction, the same is not true for the neighbouring voxels of a node. Therefore <code>getNghVoxelValue</code> returns a structure that contains both the value of the neighbour node field and an active flag.</p> <p>Instead, explicitly checking if the neighbour voxel is active or not, we use the parameter of getNghVoxelValue, which define value returned by the method for non-active voxels. We set the parameter to zero (<code>returnValueIfVoxelIsNotActive</code>), which is the neutral element of the sum operator.</p> <p>The final thing to is to run our new Container from the main function and export the resulting data to vtk as shown below.</p> Neon/tutorials/staggered-grids/src/staggeredGrid.cpp<pre><code>    {  // Accessing nodes from voxels\n       // For each voxel we loop around all nodes, we sum their values and divide the result by 8.\n       // At the end of the container we expect to have the following values:\n       // -- 1 for any corner node\n       // -- 2 for any node on an edge of our domain\n       // -- 3 for any node on a face\n       // -- 4 for internal nodes\n        UserContainers::sumVoxelsOnNodesAndDivideBy8(temperature,\n                                                     density)\n            .run(Neon::Backend::mainStreamIdx);\n\n        exportingToVti(\"0002\");\n    }\n\n    return 0;\n}\n</code></pre> <p>Warning</p> <p>The <code>sumVoxelsOnNodesAndDivideBy8</code> Container represents a stencil opertation, therefore the halo of the temperature field must be up to  date before executing the container.</p> <p></p>"},{"location":"learn/the-bases/01-system-level/","title":"System Level","text":""},{"location":"learn/the-bases/01-system-level/#the-system-level","title":"The System Level","text":"<p>The System abstraction shields the rest of Neon from architecture and hardware-specific mechanisms. Therefore, this abstraction level should be invisible to the final Neon users.</p> <p>The System defines an object-oriented interface to manage resources and requires the following backend capabilities:</p> <p>Memory Management:     This allows Neon to create device buffers and move data between devices or host.</p> <p>Queue-based Run-time Model:     Neon uses a queue-based model to abstract asynchronous kernels running on the same device. It is a generic model widely used at the hardware level and other programming models. For example, in CUDA, Streams represent command queues, while Events are the mechanism to inject dependencies between different queues.</p> <p>Lambda Functions:     Neon leverages the expressiveness of lambda functions to lessen the complexity of authoring multi-GPU applications.</p> <p>Therefore, to port Neon to a new accelerator, only the Neon System abstraction has to be implemented; higher levels in Neon can remain unchanged.</p>"},{"location":"learn/the-bases/02-the-set-level/","title":"Set Level","text":""},{"location":"learn/the-bases/02-the-set-level/#the-set-level","title":"The Set Level","text":""},{"location":"learn/the-bases/03-domain-level/","title":"Domain Level","text":""},{"location":"learn/the-bases/03-domain-level/#the-domain-level","title":"The Domain Level","text":"<p>Neon Domain level\u2019s goal is to provide users with simple mechanisms for some specific domains. Currently, Neon focus on those domains where a regular cartesian discretizations are leveraged. Using a simple example will look at how the level mechanisms can be used.</p>"},{"location":"learn/the-bases/03-domain-level/#working-with-dense-domains","title":"Working with dense domains","text":"<p>Let\u2019s use aspects of implicit geometries and the finite difference method to check out some elements of Neon. Our goal for this tutorial is to first define a sphere on a discrete dense domain via the level set method, then design two operators: one to expand the sphere and the other to compute its gradient.</p> <p>We divide the tutorial in the following steps steps:</p> <ol> <li>Neon backend - Choosing the hardware for the computation</li> <li>Neon grid - Setting up a dense cartesian discretization</li> <li>Neon field - Initializing the level set of a sphere</li> <li>Neon map containers Expanding the sphere</li> <li>Neon stencil containers - Computing the grad of the sphere</li> </ol> <p>The complete code of the tutorial is located in the <code>Neon/tutorials/introduction/domainLevel</code> directory. However, in the following, we\u2019ll start with an empty main function and guide you step by step.</p> <p>"},{"location":"learn/the-bases/03-domain-level/#neon-backend-choosing-the-hardware-for-the-computation","title":"Neon backend: choosing the hardware for the computation","text":"<p>We start our program by specifying the hardware we want to use. The process is introduced in depth by the Neon Set Level section.</p> Neon/tutorials/introduction/domainLevel/domainLevel.cpp<pre><code>int main(int, char**)\n{\n    // Step 1 -&gt; Neon backend: choosing the hardware for the computation\n    Neon::Backend backend = [] {\n        Neon::init();\n        // auto runtime = Neon::Runtime::openmp;\n        auto runtime = Neon::Runtime::stream;\n        // We are overbooking XPU 0 three times\n        std::vector&lt;int&gt; xpuIds{0, 0, 0};\n        Neon::Backend    backend(xpuIds, runtime);\n        // Printing some information\n        NEON_INFO(backend.toString());\n        return backend;\n    }();\n\n    return 0;\n}\n</code></pre> <p>Just briefly, through a <code>Neon::Backend</code> object, we declare the runtime type (CUDA streams or OpenMP) and a list of resources IDs. In our example, we target the first GPU in the system (GPU ID 0) as it\u2019s a typical configuration; however, we overbook the GPU three times to showcase the multi-GPU capabilities.</p> <p>Note</p> <p>Overbooking a GPU can have a negative impact on performance. However, checking out (or debugging) multi-GPU mechanisms using a single GPU is quite handy.</p> <p>Finally, before returning from the main, we also log some hardware information on the terminal to check that everything is as expected.</p> <p>Warning</p> <p>Remember always to call <code>Neon::init();</code> to ensure that the Neon runtime has been initialized.  The function can be call more than once. </p> <p>By testing out our first code draft, we get the following output on the terminal:</p> Execution output<pre><code>$ ./tutorial-domainLevel \n[20:33:16] Neon: CpuSys_t: Loading info on CPU subsystem\n[20:33:16] Neon: GpuSys_t: Loading info on GPU subsystem 2 GPUs were detected.\n[20:33:16] Neon: Backend_t (0x7ffd171aad40) - [runtime:stream] [nDev:3] [dev0:0 NVIDIARTXA6000] [dev1:0 NVIDIARTXA6000] [dev2:0 NVIDIARTXA6000] \n</code></pre> <p>In particular, the last line describes the selected backend by providing the type, the number of devices as well as the device name. In this case, we are working on an Nvidia A4000 GPU.</p> <p>"},{"location":"learn/the-bases/03-domain-level/#neon-grid-setting-up-the-cartesian-discretization","title":"Neon grid: setting up the cartesian discretization","text":"<p>Let\u2019s now extend our previous code by defining a cartesian discretization for our problem; for example, let\u2019s create our sphere on top of a 100^3 grid.</p> Neon/tutorials/introduction/domainLevel/domainLevel.cpp<pre><code>    // ...\n\n    // Step 2 -&gt; Neon grid: setting up a 100^3 dense cartesian domain\n    const int32_t  n = 100;\n    Neon::index_3d dim(n, n, n);     // Size of the domain\n    const double   voxelEdge = 1.0;  // Size of a voxel edge\n\n    using Grid = Neon::domain::eGrid;  // Selecting one of the grid provided by Neon\n    Grid grid = [&amp;] {\n        Neon::domain::Stencil gradStencil([] {\n            // We use a center difference scheme to compute the grad\n            // The order of the points is important,\n            // as we'll leverage the specific order when computing the grad.\n            // First positive direction on x, y and z,\n            // then negative direction on x, y, z respectively.\n            return std::vector&lt;Neon::index_3d&gt;{\n                {1, 0, 0},\n                {0, 1, 0},\n                {0, 0, 1},\n                {-1, 0, 0},\n                {0, -1, 0},\n                {0, 0, -1}};\n        }());\n\n        // Actual Neon grid allocation\n        Grid grid(\n            backend,  // &lt;- Passing the target hardware for the computation\n            dim,      // &lt;- Dimension of the regular grid used for the discretizasion.\n            [&amp;](const Neon::index_3d&amp;) -&gt; bool {\n                // We are looking for a dense domain,\n                // so we are interested in all the points in the grid.\n                return true;\n            },             // &lt;-  defining the active cells.\n            gradStencil);  // &lt;- Stencil that will be used during computations on the grid\n\n        // Exporting some information\n        NEON_INFO(grid.toString());\n        grid.ioDomainToVtk(\"domain\");\n\n        return grid;\n    }();\n\n    return 0;\n}\n</code></pre> <p>Neon Domain provides various grid implementations, and they all share the same interface. Dense, element sparse and block sparse are some of the provided grids (description and comparison of all the grids are under work). In our example, we selected an element sparse grid (Neon::domain::eGrid); however, we create a C++ alias instead of directly using the grid type (line 43). This approach allows us to switch in the future from one grid to another by just redefining the alias.</p> <p>Note</p> <p>Switching from one grid to another, like in the example, is done at compile time. Neon does not directly support dynamic grid switching. However, it can be implemented by the users via std::variant.</p> <p>The main information to provide is:</p> <p>For the initialization of the grid (line 108), we provide the following information:</p> <ul> <li>dimension of the discretization box,</li> <li>the set of cells of the discretization box that we are interested in,</li> <li>the hardware to be used for any computation,</li> <li>and finally a stencil which is basically defined as a vector of offsets (line 44).</li> </ul> <p>A stencil may be seen as an uncommon parameter to provide as part of a grid initialization. The stencil is the union of all the stencils that are used by any computation on the grid.</p> <p>Neon uses the stencil information for many critical optimization aspects. An ad-hoc compiler could automatically extract what stencil are used. However, Neon is developed as a C++ library, so it must rely on the user to retrieve such information.</p> <p>Running again the tutorial with the additional code lines we obtain the following output:</p> Execution output<pre><code>$ ./tutorial-domainLevel \n[20:33:16] Neon: CpuSys_t: Loading info on CPU subsystem\n[20:33:16] Neon: GpuSys_t: Loading info on GPU subsystem 2 GPUs were detected.\n[20:33:16] Neon: Backend_t (0x7ffd171aad40) - [runtime:stream] [nDev:3] [dev0:0 NVIDIARTXA6000] [dev1:0 NVIDIARTXA6000] [dev2:0 NVIDIARTXA6000] \n[20:33:18] Neon: [Domain Grid]:{eGrid}, [Background Grid]:{(100, 100, 100)}, [Active Cells]:{1000000}, [Idx Distribution]:{(333334,333333,333333)}, [Backend]:{Backend_t (0x55ce949fd450) - [runtime:stream] [nDev:3] [dev0:0 NVIDIARTXA6000] [dev1:0 NVIDIARTXA6000] [dev2:0 NVIDIARTXA6000] }\n</code></pre> <p>By logging the grid information (<code>NEON_INFO(grid.toString());</code> on line 71), we can check some information about the grid. The last terminal line shows the selected grid type (eGrid in this case), the dimension of the grid, the number of active cells, as well as the number of cells per XPU.</p> <p>By calling <code>ioDomainToVtk</code> method, we can also inspect the created domain (<code>grid</code>) via Paraview as the code generates a vtk file (<code>domain</code>). With an application working on a dense domain, the Paraview will show all the cells in the discretization box as active. Moreover, it will show the mapping between cells and hardware devices as reported in the following picture:</p> <p></p> <p>"},{"location":"learn/the-bases/03-domain-level/#neon-field-defining-data-over-the-cartesian-discretization","title":"Neon field: defining data over the cartesian discretization","text":"<p>Let\u2019s now create some metadata on top of our 100^3 cartesian discretization to store the level set of a sphere. Neon fields, which are allocated from a Neon grid, are the tool for the task. A Neon field is characterized by the type of each cell and the number of components stored in each cell (we call it cardinality of the field). The cell type is defined at compile time, while cardinality can be defined either at compile time or at runtime. In our example, we use the runtime version.</p> Neon/tutorials/introduction/domainLevel/domainLevel.cpp<pre><code>    //...\n\n    // Step 3 -&gt; Neon field: initializing a sphere through its signed distance function\n\n    auto sphere = [dim, n, voxelEdge, &amp;grid] {\n        // Creating a scalar field over the grid.\n        // Inactive cells will get associated with a default value of -100 */\n        auto sphere = grid.newField&lt;double&gt;(\"sphere\",  // &lt;- Given name of the field.\n                                            1,         // &lt;- Number of field's component per grid point.\n                                            -100);     // &lt;- Default value for non active points.\n\n        const double r = (n * voxelEdge / 2) * .5;\n\n        // We initialize the field with the level set of a sphere.\n        // We leverage the forEachActiveCell method to easily iterate over the active cells.\n        sphere.forEachActiveCell([&amp;](const Neon::index_3d&amp; idx, int, double&amp; value) {\n            double sdf = sdfCenteredSphere(idx, dim, voxelEdge, r);\n            value = sdf;\n        });\n        return sphere;\n    }();\n\n    // Exporting some information of the level set field on terminal and on a vtk file.\n    NEON_INFO(sphere.toString());\n    sphere.ioToVtk(\"sphere-levelSet\", \"levelSet\");\n\n\n    return 0;\n}\n</code></pre> <p></p> <p>"},{"location":"learn/the-bases/03-domain-level/#neon-map-containers-expanding-the-sphere-via-a-level-set","title":"Neon map containers: expanding the sphere via a level set","text":"<p>Let\u2019s now manipulate the sdf to expand zero level set of the sphere. The operation can be simply implemented by adding a constant to all the cells of the grid. The result will be a level set field (not a signed distance function).</p> <p>At the moment the values of the <code>sphere</code> field are stored on the host, indeed working on the host side is the only way we can do IO type of operations on Neon grids. To move the data to the XPUs for the computation we just need to call the <code>updateIO</code>method.</p> <p>Warning</p> <p>All Neon operations related to runnig computation or moving data have a asynchronous semantic. At the domain level it is up to the user to handle any sort of synchronization manually. </p> Neon/tutorials/introduction/domainLevel/domainLevel.cpp<pre><code>    // ...\n\n    // Step 4 -&gt; Neon map containers: expanding the sphere via a level set\n\n    {  // loading the sphere to XPUs\n        sphere.updateCompute(Neon::Backend::mainStreamIdx);\n    }\n    // Run a container that adds a value to the sdf sphere.\n    // The result is a level set of an expanded sphere (not more a sdf).\n    // We run the container asynchronously on the main stream\n    expandLevelSet(sphere, 9.0).run(Neon::Backend::mainStreamIdx);\n\n    {  // Moving asynchronously the values of the newly computed\n        // level set values to the host\n        sphere.updateIO(Neon::Backend::mainStreamIdx);\n        // Waiting for the transfer to complete.\n        backend.sync(Neon::Backend::mainStreamIdx);\n        // Exporting once again the field to vtk\n        sphere.ioToVtk(\"extended-sphere-levelSet\", \"levelSet\");\n    }\n\n    return 0;\n}\n</code></pre> <p>The <code>expandLevelSet</code> method returns a Neon Container, which is the equivalent of a kernel in CUDA. A Neon Container executes in parallel a computation over all the XPU devices defined by the Backend. The following is the structure of the Container used to expand our sphere.</p> <p>A Container can be generated from a Neon grid and is composed by two parts: a Loading Lambda where user declare what files are going to be used for the computation and a Compute Lambda, which contains the actual XPU code.</p> <p>Once a field is loaded we can read and write its values by using a reference to a <code>Idx</code> (which is passed to the Compute Lambda by the Neon runtime) and specifying what component of the field we are interested in. Once a Container is created, it can be executed by calling the <code>run</code> method (see the above code).</p> Neon/tutorials/introduction/domainLevel/expandLevelSet.cu<pre><code>template &lt;typename Field&gt;\nauto expandLevelSet(Field&amp; sdf,\n                    double expansion)\n    -&gt; Neon::set::Container\n{\n    return sdf.getGrid().getContainer(\n        \"ExpandLevelSet\",\n        // Neon Loading Lambda\n        [&amp;, expansion](Neon::set::Loader&amp; L) {\n            auto&amp; px = L.load(sdf);\n\n            // Neon Compute Lambda\n            return [=] NEON_CUDA_HOST_DEVICE(\n                       const typename Field::Idx&amp; cell) mutable {\n                px(cell, 0) -= expansion;\n            };\n        });\n}\n</code></pre> <p></p> <p>"},{"location":"learn/the-bases/03-domain-level/#neon-stencil-containers-computing-the-grad-of-the-level-set-field","title":"Neon stencil containers: computing the grad of the level set field","text":"Neon/tutorials/introduction/domainLevel/domainLevel.cpp<pre><code>    // ...\n\n    // Step 5 -&gt; Neon stencil containers: computing the grad of the level set field\n    auto grad = grid.newField&lt;double&gt;(\"grad\",  // &lt;- Given name of the field.\n                                      3,       // &lt;- Number of field's component per grid point.\n                                      0);      // &lt;- Default value for non active points.\n\n    Neon::set::HuOptions huOptions(Neon::set::TransferMode::get,\n                                   true);\n    sphere.haloUpdate(huOptions);\n\n    // Execution of a container that computes the gradient of the sphere\n    computeGrad(sphere, grad, voxelEdge).run(Neon::Backend::mainStreamIdx);\n\n    {  // Moving the grad data onto the host and exporting it to vtk\n        grad.updateIO(Neon::Backend::mainStreamIdx);\n        backend.sync(Neon::Backend::mainStreamIdx);\n        grad.ioToVtk(\"extended-sphere-grad\", \"grad\");\n    }\n\n    return 0;\n</code></pre> Neon/tutorials/introduction/domainLevel/expandSphere.cu<pre><code>/**\n * A function that generates a Neon Container to compute the grad over a scalar field.\n * Note: in Neon only constant field can be used as input for stencil computation\n */\ntemplate &lt;typename Field&gt;\nauto computeGrad(const Field&amp; levelSetField /** input scalar field we want to compute the grad.*/,\n                 Field&amp;       gradField /** input scalar field we want to compute the grad.*/,\n                 double       h)\n    -&gt; Neon::set::Container\n{\n    if (levelSetField.getCardinality() != 1 || gradField.getCardinality() != 3) {\n        // We check that the level set field is a scalar field,\n        // while the gradient is a three component field.\n        NEON_THROW_UNSUPPORTED_OPERATION(\"Wrong cardinality detected.\");\n    }\n\n    // The following Neon compute-lambda works with the assumption that the first elements of the stencil\n    // given to the grid initialization are as follow:\n    //\n    //      {1, 0, 0},\n    //      {0, 1, 0},\n    //      {0, 0, 1},\n    //      {-1, 0, 0},\n    //      {0, -1, 0},\n    //      {0, 0, -1}\n    return levelSetField.getGrid().getContainer(\n        \"computeGrad\",\n        // Neon Loading Lambda\n        [&amp;, h](Neon::set::Loader&amp; L) {\n            // Loading the sdf field for a stencil type of computation\n            // as we will be using a 6 point stencil to compute the gradient\n            auto&amp; levelSet = L.load(levelSetField, Neon::Compute::STENCIL);\n            auto&amp; grad = L.load(gradField);\n\n            // We can nicely compute the inverse of the spacing in the loading lambda\n            const auto oneOverTwoH = 1. / (2.0 * h);\n\n            // Neon Compute Lambda\n            return [=] NEON_CUDA_HOST_DEVICE(\n                       const typename Field::Idx&amp; cell) mutable {\n                // Central difference\n                for (int i = 0; i &lt; 3; i++) {\n                    auto upIdx = i;\n                    auto dwIdx = i + 3;\n\n                    auto [valUp, isValidUp] = levelSet.nghVal(cell, upIdx, 0, 0);\n                    auto [valDw, isValidDw] = levelSet.nghVal(cell, dwIdx, 0, 0);\n\n                    if (!isValidUp || !isValidDw) {\n                        grad(cell, 0) = 0;\n                        grad(cell, 1) = 0;\n                        grad(cell, 2) = 0;\n                        break;\n                    } else {\n                        grad(cell, i) = (valUp - valDw) / oneOverTwoH;\n                    }\n                }\n            };\n        });\n}\n</code></pre> <p>Staggered Grids</p>"},{"location":"learn/the-bases/04-skeleton-level/","title":"Skeleton Level","text":""},{"location":"learn/the-bases/04-skeleton-level/#the-skeleton-level","title":"The Skeleton Level","text":"<p>"},{"location":"learn/the-bases/04-skeleton-level/#neon-stencil-containers-computing-the-grad-of-the-level-set-field","title":"Neon stencil containers: computing the grad of the level set field","text":"Neon/tutorials/introduction/domainLevel/domainLevel.cpp<pre><code>   // ...\n\n    Neon::skeleton::Skeleton skl(data.getBackend());\n    Neon::skeleton::Options  opt(occ, transfer);\n    auto                     fR = data.getGrid().template newPatternScalar&lt;T&gt;();\n\n    fR() = scalarVal;\n\n    data.getBackend().syncAll();\n\n\n    {  // SKELETON\n        auto&amp; X = data.getField(FieldNames::X);\n        auto&amp; Y = data.getField(FieldNames::Y);\n\n        skl.sequence({UserTools::axpy(fR, Y, X),\n                      UserTools::laplace(X, Y),\n                      data.getGrid().dot(\"DotContainer\", Y, Y, fR)},\n                     appName, opt);\n\n        skl.ioToDot(appName + \"_\" + Neon::skeleton::OccUtils::toString(opt.occ()));\n\n        timer.start();\n        for (int i = 0; i &lt; nIterations; i++) {\n            skl.run();\n        }\n        data.getBackend().syncAll();\n        timer.stop();\n    }\n</code></pre>"},{"location":"references/api-documentation/","title":"API Documentation - Doxygen","text":"<p>Doxyten documentation for Neon users is located here:  CodeConvention.md</p>"},{"location":"references/papers-presentations/","title":"Papers","text":"Date Event Title Pdf Bibtex 2022-05-30 IPDPS-22 Neon: A Multi-GPU Programming Model for Grid-based Computations Authors\u2019 Copy Meneghin:2022:NAM"},{"location":"references/papers-presentations/#presentations","title":"Presentations","text":"Date Event Title Recordings Slides 2022-03-23 GTC-22 Neon: A Multi-GPU Programming Model for Grid-based Computations Hosted by GTC Hosted by GTC"},{"location":"references/performance-considerations/","title":"Performance Considerations","text":"<p>TODO - add some reference benchmarks</p>"}]}